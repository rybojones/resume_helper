{
  "projects": [
    {
      "id": "proj_001",
      "title": "Customer Churn Prediction Model",
      "organization": "Acme Corp",
      "dates": { "start": "2023-03", "end": "2024-01" },
      "summary": "Built an end-to-end churn prediction pipeline that reduced customer attrition by 12% in Q1 2024.",
      "description_long": "Designed and productionized a gradient-boosted classification model (XGBoost) to predict monthly subscriber churn for a 2M-customer SaaS platform. Owned the full ML lifecycle: feature engineering from raw SQL event logs, hyperparameter tuning via cross-validation, Docker-based deployment, and a Grafana dashboard for ongoing monitoring. Collaborated with the CX team to operationalize intervention workflows triggered by model scores.",
      "role": "Lead Data Scientist",
      "skills": ["Python", "XGBoost", "SQL", "Docker", "Grafana"],
      "role_tags": ["data_scientist", "mle"],
      "impact": [
        "Reduced churn by 12% in Q1 2024",
        "Saved 8 hours/week of manual analyst work",
        "Model served 2M customers in production with <50ms latency"
      ],
      "keywords": ["churn", "classification", "pipeline", "deployment", "monitoring"],
      "include_by_default": true,
      "notes": "Strong fit for any role requiring end-to-end ML ownership."
    },
    {
      "id": "proj_002",
      "title": "Real-Time Fraud Detection System",
      "organization": "FinServe Inc",
      "dates": { "start": "2022-06", "end": "2023-02" },
      "summary": "Architected a real-time streaming fraud detection system processing 50K transactions/minute with <100ms P99 latency.",
      "description_long": "Led architecture and implementation of a streaming fraud detection platform on Apache Kafka + Flink. Built ensemble models (LightGBM + rule engine) trained on 3 years of transaction history. Designed feature store backed by Redis for low-latency feature serving. Worked closely with fraud ops to tune precision/recall thresholds and built an analyst-facing review queue integrated with the existing case management system.",
      "role": "Senior ML Engineer",
      "skills": ["Python", "Kafka", "Flink", "LightGBM", "Redis", "AWS"],
      "role_tags": ["mle", "data_engineer"],
      "impact": [
        "Caught 34% more fraudulent transactions vs. legacy rule-based system",
        "Reduced false-positive rate by 18%, lowering friction for legitimate customers",
        "Processed 50K transactions/minute at <100ms P99 latency"
      ],
      "keywords": ["fraud", "streaming", "real-time", "feature store", "ensemble"],
      "include_by_default": true,
      "notes": "Best for roles emphasizing production ML systems and low-latency requirements."
    },
    {
      "id": "proj_003",
      "title": "NLP-Powered Support Ticket Classifier",
      "organization": "HelpDesk Co",
      "dates": { "start": "2021-09", "end": "2022-05" },
      "summary": "Fine-tuned a BERT-based classifier that auto-routed 70% of incoming support tickets, cutting average handle time by 25%.",
      "description_long": "Fine-tuned a DistilBERT model on 200K labeled support tickets to classify intent and route to the correct tier-1/tier-2 queue. Built a FastAPI inference service deployed on GCP Cloud Run with auto-scaling. Implemented an active learning loop so support agents could flag mispredictions, which fed back into monthly retraining. Delivered a Looker dashboard tracking routing accuracy and queue volume by category.",
      "role": "NLP Engineer",
      "skills": ["Python", "HuggingFace Transformers", "FastAPI", "GCP", "Looker"],
      "role_tags": ["data_scientist", "nlp_engineer"],
      "impact": [
        "Auto-routed 70% of tickets with 91% accuracy",
        "Reduced average handle time by 25%",
        "Active learning loop improved accuracy by 4 pp over 6 months"
      ],
      "keywords": ["NLP", "BERT", "classification", "active learning", "FastAPI"],
      "include_by_default": false,
      "notes": "Include for NLP/LLM-adjacent roles or roles that value inference service experience."
    }
  ]
}
